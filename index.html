<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
  body {
    font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 18px;
    margin-left: auto;
    margin-right: auto;
    width: 1100px;
  }

  h1 {
    font-size: 32px;
    font-weight: 300;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px;
    -moz-border-radius: 10px;
    -webkit-border-radius: 10px;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px;
    -moz-border-radius: 10px;
    -webkit-border-radius: 10px;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px;
    -moz-border-radius: 10px;
    -webkit-border-radius: 10px;
  }

  img.rounded {
    border: 1px solid #eeeeee;
    border-radius: 10px;
    -moz-border-radius: 10px;
    -webkit-border-radius: 10px;
  }

  a:link,
  a:visited {
    color: #1367a7;
    text-decoration: none;
  }

  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big {
    /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
      0px 0px 1px 1px rgba(0, 0, 0, 0.35),
      /* The top layer shadow */
      5px 5px 0 0px #fff,
      /* The second layer */
      5px 5px 1px 1px rgba(0, 0, 0, 0.35),
      /* The second layer shadow */
      10px 10px 0 0px #fff,
      /* The third layer */
      10px 10px 1px 1px rgba(0, 0, 0, 0.35),
      /* The third layer shadow */
      15px 15px 0 0px #fff,
      /* The fourth layer */
      15px 15px 1px 1px rgba(0, 0, 0, 0.35),
      /* The fourth layer shadow */
      20px 20px 0 0px #fff,
      /* The fifth layer */
      20px 20px 1px 1px rgba(0, 0, 0, 0.35),
      /* The fifth layer shadow */
      25px 25px 0 0px #fff,
      /* The fifth layer */
      25px 25px 1px 1px rgba(0, 0, 0, 0.35);
    /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }

  .paper-big {
    /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
      0px 0px 1px 1px rgba(0, 0, 0, 0.35);
    /* The top layer shadow */

    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper {
    /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
      0px 0px 1px 1px rgba(0, 0, 0, 0.35),
      /* The top layer shadow */
      5px 5px 0 0px #fff,
      /* The second layer */
      5px 5px 1px 1px rgba(0, 0, 0, 0.35),
      /* The second layer shadow */
      10px 10px 0 0px #fff,
      /* The third layer */
      10px 10px 1px 1px rgba(0, 0, 0, 0.35);
    /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
    top: 50%;
    transform: translateY(-50%);
  }

  hr {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>

<html>

<head>
  <title>eWand: A calibration framework for wide baseline frame-based and event-based camera systems</title>
  <meta property="og:image" content="Path to my teaser.png" />
  <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
  <meta property="og:title" content="eWand: A calibration framework for wide baseline frame-based and event-based camera systems" />
  <meta property="og:description" content="Paper description." />

  <!-- Get from Google Analytics -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src=""></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-75863369-6');
  </script>
</head>

<body>
  <br>
  <center>
    <span style="font-size:36px">eWand: A calibration framework for wide baseline frame-based and event-based camera systems</span>
    <table align=center width=990px>
      <table align=center width=990px>
        <tr>
          <td align=center width=110px>
            <center>
              <span style="font-size:24px"><a href="https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/kognitive-systeme/the-chair/staff/thomas-gossard/">Thomas Gossard*</a></span>
            </center>
          </td>
          <td align=center width=110px>
            <center>
              <span style="font-size:24px"><a href="https://andreasaziegler.github.io/">Andreas Ziegler*</a></span>
            </center>
          </td>
          <td align=center width=100px>
            <center>
              <span style="font-size:24px">Levin Kolmar</span>
            </center>
          </td>
          <td align=center width=100px>
            <center>
              <span style="font-size:24px"><a href="https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/kognitive-systeme/the-chair/staff/jonas-tebbe/">Jonas Tebbe</a></span>
            </center>
          </td>
          <td align=center width=100px>
            <center>
              <span style="font-size:24px"><a href="https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/kognitive-systeme/the-chair/staff/prof-dr-andreas-zell/">Andreas Zell</a></span>
            </center>
          </td>
        </tr>
      </table>
      <table align=center width=990px>
        <span style="font-size:24px">*equal contribution</span>
      </table>
      <table align=center width=250px>
        <tr>
          <td align=center width=120px>
            <center>
              <span style="font-size:24px"><a href='https://arxiv.org/pdf/2309.12685.pdf'>[Paper]</a></span>
            </center>
          </td>
          <td align=center width=120px>
            <center>
							<span style="font-size:24px"><a href='https://github.com/cogsys-tuebingen/ewand'> [Code]</a></span><br>
            </center>
          </td>
          <td align=center width=120px>
            <center>
							<span style="font-size:24px"><a href='https://github.com/cogsys-tuebingen/ewand'> [CAD]</a></span><br>
            </center>
          </td>
        </tr>
      </table>
    </table>
  </center>

  <center>
    <table align=center width=850px>
      <tr>
        <td width=260px>
          <center>
            <img class="round" style="width:600px" src="./resources/teaser.png" />
          </center>
        </td>
      </tr>
    </table>
    <table align=center width=850px>
      <tr>
        <td>
          <center>
            <i>An overview of our proposed calibration method.</i>
          </center>
        </td>
      </tr>
    </table>
  </center>

  <hr>

  <table align=center width=850px>
    <center>
      <h1>Abstract</h1>
    </center>
    <tr>
      <td>
          Accurate calibration is crucial for using multiple cameras to triangulate the position of objects precisely. However, it is also a time-consuming process that needs to be repeated for every displacement of the cameras. The standard approach is to use a printed pattern with known geometry to estimate the intrinsic and extrinsic parameters of the cameras. The same idea can be applied to event-based cameras, though it requires extra work. By using frame reconstruction from events, a printed pattern can be detected. A blinking pattern can also be displayed on a screen. Then, the pattern can be directly detected from the events. Such calibration methods can provide accurate intrinsic calibration for both frame- and event-based cameras. However, using 2D patterns has several limitations for multi-camera extrinsic calibration, with cameras possessing highly different points of view and a wide baseline. The 2D pattern can only be detected from one direction and needs to be of significant size to compensate for its distance to the camera. This makes the extrinsic calibration time-consuming and cumbersome. To overcome these limitations, we propose <b>eWand</b>, a new method that uses blinking LEDs inside opaque spheres instead of a printed or displayed pattern. Our method provides a faster, easier-to-use extrinsic calibration approach that maintains high accuracy for both event- and frame-based cameras.
      </td>
    </tr>
  </table>
  <br>

  <hr>
  <center>
    <h1>Talk</h1>
  </center>
  <p align="center">
    <iframe width="660" height="395" src="https://www.youtube.com/embed/Yd_Bsltdfi4" frameborder="0"
      allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
  </p>

  <!--
  <table align=center width=800px>
    <br>
    <tr>
      <center>
        <span style="font-size:28px"><a href=''>[Slides]</a>
        </span>
      </center>
    </tr>
  </table>
  <hr>
  -->

  <!--
  <center>
    <h1>Code</h1>
  </center>

  <table align=center width=420px>
    <center>
      <tr>
        <td>
        </td>
      </tr>
    </center>
  </table>
  <table align=center width=400px>
    <tr>
      <td align=center width=400px>
        <center>
      <td><img class="round" style="width:450px" src="./resources/method_diagram.png" /></td>
      </center>
      </td>
    </tr>
  </table>
  <table align=center width=850px>
    <center>
      <tr>
        <td>
          Short description if wanted
        </td>
      </tr>
    </center>
  </table>
  <table align=center width=800px>
    <br>
    <tr>
      <center>
        <span style="font-size:28px">&nbsp;<a href='https://github.com/richzhang/webpage-template'>[GitHub]</a>
      </center>
      </span>
  </table>
  <br>
  <hr>
  -->

  <table align=center width=450px>
    <center>
      <h1>Paper</h1>
    </center>
    <tr>
      <td><a href="https://arxiv.org/pdf/2309.12685.pdf"><img class="layered-paper-big" style="height:175px" src="./resources/paper.png" /></a></td>
      <td><span style="font-size:14pt">T. Gossard*, A. Ziegler*, L. Kolmar, J. Tebbe, A. Zell.<br>
          <a href="https://arxiv.org/pdf/2309.12685.pdf"><b>eWand: A calibration framework for wide baseline frame-based and event-based camera systems.</b></a><br>
          <!--In Conference, 20XX.<br>-->
          (hosted on <a href="">ArXiv</a>)<br>
          <!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
          <span style="font-size:4pt"><a href="https://arxiv.org/pdf/2309.12685.pdf"><br></a>
          </span>
      </td>
    </tr>
  </table>
  <br>

  <table align=center width=600px>
    <tr>
      <td><span style="font-size:14pt">
          <center>
            <a href="./resources/bibtex.txt">[Bibtex]</a>
          </center>
      </td>
    </tr>
  </table>

  <hr>
  <br>

  <table align=center width=900px>
    <tr>
      <td width=400px>
        <left>
          <center>
            <h1>Acknowledgements</h1>
          </center>
          This research was funded by <a href="https://ai.sony">Sony AI</a>.
        </left>
      </td>
    </tr>
  </table>

  <br>
</body>

</html>
